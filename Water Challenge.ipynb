{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3a0a637d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch as pt\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "625629e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_data = pd.read_csv('Data_climate_indices_V2.csv', index_col=0)\n",
    "\n",
    "# Finding the overall training and testing data.\n",
    "\n",
    "training = climate_data[1:361]\n",
    "testing = climate_data[361:len(climate_data)]\n",
    "\n",
    "# Splitting the x and y values for training and testing.\n",
    "\n",
    "train_x = training[training.columns[1:training.shape[1]-1]]\n",
    "train_y = training[training.columns[training.shape[1] -1:]].values[1:]\n",
    "\n",
    "test_x = testing[testing.columns[1:testing.shape[1]-1]]\n",
    "test_y = testing[testing.columns[testing.shape[1] -1:]].values[1:]\n",
    "\n",
    "# Normalizing the training and testing variables.\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "train_x_scaled = min_max_scaler.fit_transform(train_x)\n",
    "test_x_scaled = min_max_scaler.fit_transform(test_x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0150be0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(344, 15, 43)\n",
      "(344,)\n"
     ]
    }
   ],
   "source": [
    "# Creating the data with shifts for training.\n",
    "\n",
    "logs = 15\n",
    "shifted_x_train = []\n",
    "shifted_y_train = []\n",
    "\n",
    "for index in range(logs,train_x.shape[0] - 1):\n",
    "    shifted_x_train.append(train_x_scaled[index - logs : index])\n",
    "    shifted_y_train.append(train_y[index][0])\n",
    "\n",
    "shifted_x_train, shifted_y_train = np.array(shifted_x_train), np.array(shifted_y_train)\n",
    "\n",
    "print(shifted_x_train.shape)\n",
    "print(shifted_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cc08623e",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_model = Sequential()\n",
    "learning_model.add(LSTM(units = 50, return_sequences = True, input_shape=(logs,train_x.shape[1])))\n",
    "learning_model.add(Dropout(0.2))\n",
    "learning_model.add(LSTM(units = 50))\n",
    "learning_model.add(Dropout(0.2))\n",
    "learning_model.add(Dense(4))\n",
    "learning_model.add(Dense(4))\n",
    "learning_model.add(Dense(4))\n",
    "learning_model.add(Dense(4))\n",
    "learning_model.add(Dense(4))\n",
    "learning_model.add(Dense(4))\n",
    "learning_model.add(Dense(4))\n",
    "learning_model.add(Dense(4))\n",
    "learning_model.add(Dense(4))\n",
    "learning_model.add(Dense(4))\n",
    "\n",
    "\n",
    "learning_model.compile(optimizer = 'adam' , loss = 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "659a2ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "29/29 [==============================] - 18s 23ms/step - loss: 12940.4912\n",
      "Epoch 2/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 10873.1631\n",
      "Epoch 3/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8738.2725\n",
      "Epoch 4/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 8209.0635\n",
      "Epoch 5/600\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 8131.3394\n",
      "Epoch 6/600\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 8054.3125\n",
      "Epoch 7/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 7969.3955\n",
      "Epoch 8/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 8050.9595\n",
      "Epoch 9/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 8014.0908\n",
      "Epoch 10/600\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 7925.7319\n",
      "Epoch 11/600\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 8025.1753\n",
      "Epoch 12/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 7926.2769\n",
      "Epoch 13/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 7995.6040\n",
      "Epoch 14/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 7906.9507\n",
      "Epoch 15/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 8032.8706\n",
      "Epoch 16/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 7931.5044\n",
      "Epoch 17/600\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 8019.3784\n",
      "Epoch 18/600\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 8076.5532\n",
      "Epoch 19/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 7928.7495\n",
      "Epoch 20/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 8019.7632\n",
      "Epoch 21/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 7879.9097\n",
      "Epoch 22/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 7891.4521\n",
      "Epoch 23/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 8029.8008\n",
      "Epoch 24/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 7961.3896\n",
      "Epoch 25/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 7946.8154\n",
      "Epoch 26/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 8128.0220\n",
      "Epoch 27/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7912.8677\n",
      "Epoch 28/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 7970.8345\n",
      "Epoch 29/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 8004.7051\n",
      "Epoch 30/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 7984.0786\n",
      "Epoch 31/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 7935.1416\n",
      "Epoch 32/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7870.5132\n",
      "Epoch 33/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 7919.5522\n",
      "Epoch 34/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 7889.8745\n",
      "Epoch 35/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 7109.6255\n",
      "Epoch 36/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 5623.1738\n",
      "Epoch 37/600\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 4963.0542\n",
      "Epoch 38/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 5110.6929\n",
      "Epoch 39/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 4784.4067\n",
      "Epoch 40/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 5120.9863\n",
      "Epoch 41/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 4844.1001\n",
      "Epoch 42/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 4452.6440\n",
      "Epoch 43/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 4694.9038\n",
      "Epoch 44/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 4567.6372\n",
      "Epoch 45/600\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 4503.9688\n",
      "Epoch 46/600\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 4477.7510\n",
      "Epoch 47/600\n",
      "29/29 [==============================] - 1s 27ms/step - loss: 4422.6753\n",
      "Epoch 48/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 4477.9370\n",
      "Epoch 49/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 4155.1060\n",
      "Epoch 50/600\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 4353.0815\n",
      "Epoch 51/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 4151.7690\n",
      "Epoch 52/600\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 4122.6089\n",
      "Epoch 53/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 3981.4626\n",
      "Epoch 54/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 4006.1382\n",
      "Epoch 55/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 4138.9829\n",
      "Epoch 56/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 3990.3005\n",
      "Epoch 57/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 4382.0522\n",
      "Epoch 58/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 3915.2524\n",
      "Epoch 59/600\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 3926.5752\n",
      "Epoch 60/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 4030.9812\n",
      "Epoch 61/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 3574.2937\n",
      "Epoch 62/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 3704.5330\n",
      "Epoch 63/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 3532.2605\n",
      "Epoch 64/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 3576.3923\n",
      "Epoch 65/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 3641.9226\n",
      "Epoch 66/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 3423.5706\n",
      "Epoch 67/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 3129.4697\n",
      "Epoch 68/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 3374.3550\n",
      "Epoch 69/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 3238.0713\n",
      "Epoch 70/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 3394.0974\n",
      "Epoch 71/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 3779.9583\n",
      "Epoch 72/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 3489.5876\n",
      "Epoch 73/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 3123.0320\n",
      "Epoch 74/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 3137.6570\n",
      "Epoch 75/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 3197.0422\n",
      "Epoch 76/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 2801.1692\n",
      "Epoch 77/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 3260.1479\n",
      "Epoch 78/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 2825.3931\n",
      "Epoch 79/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 2954.0479\n",
      "Epoch 80/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 3075.9023\n",
      "Epoch 81/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 3460.3945\n",
      "Epoch 82/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 2976.4119\n",
      "Epoch 83/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 2950.6912\n",
      "Epoch 84/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 3036.0891\n",
      "Epoch 85/600\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 3446.1843\n",
      "Epoch 86/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 2937.7283\n",
      "Epoch 87/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 2738.1799\n",
      "Epoch 88/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 2496.4287\n",
      "Epoch 89/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 2666.6174\n",
      "Epoch 90/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 3730.6794\n",
      "Epoch 91/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 2764.8982\n",
      "Epoch 92/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 2936.3418\n",
      "Epoch 93/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 3279.7471\n",
      "Epoch 94/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 2816.6736\n",
      "Epoch 95/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 2833.7036\n",
      "Epoch 96/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 2206.5127\n",
      "Epoch 97/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 2695.3579\n",
      "Epoch 98/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 2328.9783\n",
      "Epoch 99/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 2136.9038\n",
      "Epoch 100/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 2356.5576\n",
      "Epoch 101/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 2222.3088\n",
      "Epoch 102/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 2994.5667\n",
      "Epoch 103/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 2946.4832\n",
      "Epoch 104/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 2702.2141\n",
      "Epoch 105/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 2663.4702\n",
      "Epoch 106/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 2619.5366\n",
      "Epoch 107/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 2630.7532\n",
      "Epoch 108/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 2271.0962\n",
      "Epoch 109/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 2178.2554\n",
      "Epoch 110/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 2104.7710\n",
      "Epoch 111/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 2378.2876\n",
      "Epoch 112/600\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 2127.7283\n",
      "Epoch 113/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 2095.9417\n",
      "Epoch 114/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1891.5670\n",
      "Epoch 115/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1827.2738\n",
      "Epoch 116/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 1884.8738\n",
      "Epoch 117/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 1838.9484\n",
      "Epoch 118/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 1873.0118\n",
      "Epoch 119/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 2051.4106\n",
      "Epoch 120/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1977.0138\n",
      "Epoch 121/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1888.7579\n",
      "Epoch 122/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 1844.2499\n",
      "Epoch 123/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1907.3582\n",
      "Epoch 124/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1955.2570\n",
      "Epoch 125/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 2008.3599\n",
      "Epoch 126/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 2110.4841\n",
      "Epoch 127/600\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 2066.2012\n",
      "Epoch 128/600\n",
      "29/29 [==============================] - 1s 27ms/step - loss: 1846.2391\n",
      "Epoch 129/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 1925.2886\n",
      "Epoch 130/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 1736.5874\n",
      "Epoch 131/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 2019.3751\n",
      "Epoch 132/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 2013.4117\n",
      "Epoch 133/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1968.4940\n",
      "Epoch 134/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 2050.6394\n",
      "Epoch 135/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1758.8630\n",
      "Epoch 136/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1701.3809\n",
      "Epoch 137/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1859.3158\n",
      "Epoch 138/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1905.0336\n",
      "Epoch 139/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1345.1781\n",
      "Epoch 140/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1312.4738\n",
      "Epoch 141/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1442.8707\n",
      "Epoch 142/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1369.2495\n",
      "Epoch 143/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1343.2305\n",
      "Epoch 144/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1538.2972\n",
      "Epoch 145/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1679.1146\n",
      "Epoch 146/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1717.6522\n",
      "Epoch 147/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1447.7147\n",
      "Epoch 148/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 3365.0132\n",
      "Epoch 149/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 2249.9712\n",
      "Epoch 150/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1712.1678\n",
      "Epoch 151/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1444.5115\n",
      "Epoch 152/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1543.1152\n",
      "Epoch 153/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1413.8363\n",
      "Epoch 154/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 1917.9695\n",
      "Epoch 155/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 1567.2950\n",
      "Epoch 156/600\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 1543.0704\n",
      "Epoch 157/600\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 1484.7992\n",
      "Epoch 158/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 1250.7344\n",
      "Epoch 159/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 1436.5691\n",
      "Epoch 160/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1162.6282\n",
      "Epoch 161/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1349.5116\n",
      "Epoch 162/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1356.4945\n",
      "Epoch 163/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1323.0436\n",
      "Epoch 164/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1357.9707\n",
      "Epoch 165/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1395.2168\n",
      "Epoch 166/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1338.8217\n",
      "Epoch 167/600\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 1155.2817\n",
      "Epoch 168/600\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 1272.1859\n",
      "Epoch 169/600\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 1247.8854\n",
      "Epoch 170/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1328.6350\n",
      "Epoch 171/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1146.9518\n",
      "Epoch 172/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1345.5382\n",
      "Epoch 173/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1400.3937\n",
      "Epoch 174/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1232.2772\n",
      "Epoch 175/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1651.4192\n",
      "Epoch 176/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1501.3230\n",
      "Epoch 177/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1451.2322\n",
      "Epoch 178/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 1363.3511\n",
      "Epoch 179/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1211.0825\n",
      "Epoch 180/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1531.4088\n",
      "Epoch 181/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1540.5253\n",
      "Epoch 182/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 1360.2478\n",
      "Epoch 183/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1237.3262\n",
      "Epoch 184/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1184.2916\n",
      "Epoch 185/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1112.5819\n",
      "Epoch 186/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1004.2289\n",
      "Epoch 187/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1100.4220\n",
      "Epoch 188/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 1197.6744\n",
      "Epoch 189/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1297.5360\n",
      "Epoch 190/600\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 1328.2001\n",
      "Epoch 191/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1290.4714\n",
      "Epoch 192/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1160.6003\n",
      "Epoch 193/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1097.6631\n",
      "Epoch 194/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1021.5370\n",
      "Epoch 195/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1061.7815\n",
      "Epoch 196/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1187.6952\n",
      "Epoch 197/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1186.0460\n",
      "Epoch 198/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1203.8770\n",
      "Epoch 199/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1288.4258\n",
      "Epoch 200/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1231.0935\n",
      "Epoch 201/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1234.9468\n",
      "Epoch 202/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 974.7018\n",
      "Epoch 203/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1010.1668\n",
      "Epoch 204/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1003.5518\n",
      "Epoch 205/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1221.8887\n",
      "Epoch 206/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1298.0231\n",
      "Epoch 207/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1247.9188\n",
      "Epoch 208/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 970.4715\n",
      "Epoch 209/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 942.4175\n",
      "Epoch 210/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 957.2394\n",
      "Epoch 211/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1033.6246\n",
      "Epoch 212/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1227.9197\n",
      "Epoch 213/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1024.4543\n",
      "Epoch 214/600\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 910.3154\n",
      "Epoch 215/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1019.5782\n",
      "Epoch 216/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1087.8094\n",
      "Epoch 217/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1040.0071\n",
      "Epoch 218/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1039.9391\n",
      "Epoch 219/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 864.3430\n",
      "Epoch 220/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 874.1185\n",
      "Epoch 221/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 801.3754\n",
      "Epoch 222/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 992.6404\n",
      "Epoch 223/600\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 1047.4838\n",
      "Epoch 224/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 887.3525\n",
      "Epoch 225/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 850.8406\n",
      "Epoch 226/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 805.7937\n",
      "Epoch 227/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 799.9209\n",
      "Epoch 228/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 880.0772\n",
      "Epoch 229/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 877.0552\n",
      "Epoch 230/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1183.9993\n",
      "Epoch 231/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 2294.6318\n",
      "Epoch 232/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 2125.7390\n",
      "Epoch 233/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1950.2135\n",
      "Epoch 234/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1156.0573\n",
      "Epoch 235/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 977.7651\n",
      "Epoch 236/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 883.1564\n",
      "Epoch 237/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 857.7316\n",
      "Epoch 238/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 816.7679\n",
      "Epoch 239/600\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 860.5923\n",
      "Epoch 240/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 1017.0314\n",
      "Epoch 241/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 858.4965\n",
      "Epoch 242/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 809.1797\n",
      "Epoch 243/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 906.6306\n",
      "Epoch 244/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 817.4457\n",
      "Epoch 245/600\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 781.9160\n",
      "Epoch 246/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 879.0779\n",
      "Epoch 247/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 830.7656\n",
      "Epoch 248/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 707.9086\n",
      "Epoch 249/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 860.3925\n",
      "Epoch 250/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 768.5365\n",
      "Epoch 251/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 776.2357\n",
      "Epoch 252/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 835.8912\n",
      "Epoch 253/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 838.7370\n",
      "Epoch 254/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 727.4420\n",
      "Epoch 255/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 813.1317\n",
      "Epoch 256/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 677.9684\n",
      "Epoch 257/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 709.8620\n",
      "Epoch 258/600\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 662.8376\n",
      "Epoch 259/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 659.7487\n",
      "Epoch 260/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 665.3969\n",
      "Epoch 261/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 674.9808\n",
      "Epoch 262/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 747.5114\n",
      "Epoch 263/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 644.8053\n",
      "Epoch 264/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 731.1486\n",
      "Epoch 265/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 701.5392\n",
      "Epoch 266/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 809.2426\n",
      "Epoch 267/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 669.7677\n",
      "Epoch 268/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 711.1082\n",
      "Epoch 269/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 629.8663\n",
      "Epoch 270/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 650.1081\n",
      "Epoch 271/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 729.6954\n",
      "Epoch 272/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 697.4527\n",
      "Epoch 273/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 807.7628\n",
      "Epoch 274/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 737.3140\n",
      "Epoch 275/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 785.7565\n",
      "Epoch 276/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 675.7221\n",
      "Epoch 277/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 666.2830\n",
      "Epoch 278/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 666.7594\n",
      "Epoch 279/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 813.3896\n",
      "Epoch 280/600\n",
      "29/29 [==============================] - 1s 38ms/step - loss: 760.1056\n",
      "Epoch 281/600\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 800.5670\n",
      "Epoch 282/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 725.4492\n",
      "Epoch 283/600\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 1447.9188\n",
      "Epoch 284/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 3199.7776\n",
      "Epoch 285/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1840.7656\n",
      "Epoch 286/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1646.0231\n",
      "Epoch 287/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1234.2732\n",
      "Epoch 288/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 973.2881\n",
      "Epoch 289/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1004.0671\n",
      "Epoch 290/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 822.9496\n",
      "Epoch 291/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 696.7599\n",
      "Epoch 292/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 711.3022\n",
      "Epoch 293/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 741.6799\n",
      "Epoch 294/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 635.9947\n",
      "Epoch 295/600\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 647.6179\n",
      "Epoch 296/600\n",
      "29/29 [==============================] - 1s 35ms/step - loss: 703.0602\n",
      "Epoch 297/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 632.2957\n",
      "Epoch 298/600\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 657.3477\n",
      "Epoch 299/600\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 595.5953\n",
      "Epoch 300/600\n",
      "29/29 [==============================] - 1s 40ms/step - loss: 605.1595\n",
      "Epoch 301/600\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 554.1746\n",
      "Epoch 302/600\n",
      "29/29 [==============================] - 1s 32ms/step - loss: 643.2838\n",
      "Epoch 303/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 599.0070\n",
      "Epoch 304/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 592.9456\n",
      "Epoch 305/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 654.3727\n",
      "Epoch 306/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 610.3023\n",
      "Epoch 307/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 589.7256\n",
      "Epoch 308/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 611.0198\n",
      "Epoch 309/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 633.9908\n",
      "Epoch 310/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 624.4880\n",
      "Epoch 311/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 627.8658\n",
      "Epoch 312/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 643.8010\n",
      "Epoch 313/600\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 588.9930\n",
      "Epoch 314/600\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 573.5552\n",
      "Epoch 315/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 636.9915\n",
      "Epoch 316/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 630.3762\n",
      "Epoch 317/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 514.2084\n",
      "Epoch 318/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 544.8906\n",
      "Epoch 319/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 568.9868\n",
      "Epoch 320/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 615.1194\n",
      "Epoch 321/600\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 631.1257\n",
      "Epoch 322/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 891.8854\n",
      "Epoch 323/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 912.4167\n",
      "Epoch 324/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 655.8455\n",
      "Epoch 325/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 917.6913\n",
      "Epoch 326/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 716.6306\n",
      "Epoch 327/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 596.9235\n",
      "Epoch 328/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 561.7654\n",
      "Epoch 329/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 527.7977\n",
      "Epoch 330/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 525.6156\n",
      "Epoch 331/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 640.4111\n",
      "Epoch 332/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 756.2498\n",
      "Epoch 333/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 706.1037\n",
      "Epoch 334/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 641.4705\n",
      "Epoch 335/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 642.1807\n",
      "Epoch 336/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 638.9081\n",
      "Epoch 337/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 545.7416\n",
      "Epoch 338/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 535.4312\n",
      "Epoch 339/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 688.5295\n",
      "Epoch 340/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 616.4413\n",
      "Epoch 341/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 571.8909\n",
      "Epoch 342/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 597.8787\n",
      "Epoch 343/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 531.4012\n",
      "Epoch 344/600\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 464.0058\n",
      "Epoch 345/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 503.7781\n",
      "Epoch 346/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 593.1783\n",
      "Epoch 347/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 507.0681\n",
      "Epoch 348/600\n",
      "29/29 [==============================] - 1s 27ms/step - loss: 485.4376\n",
      "Epoch 349/600\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 499.3484\n",
      "Epoch 350/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 533.6150\n",
      "Epoch 351/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 564.8594\n",
      "Epoch 352/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 475.4186\n",
      "Epoch 353/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 494.5563\n",
      "Epoch 354/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 469.3315\n",
      "Epoch 355/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 561.4973\n",
      "Epoch 356/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 492.0660\n",
      "Epoch 357/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 556.9172\n",
      "Epoch 358/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 513.8204\n",
      "Epoch 359/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 508.1715\n",
      "Epoch 360/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 633.7117\n",
      "Epoch 361/600\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 646.4144\n",
      "Epoch 362/600\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 807.1660\n",
      "Epoch 363/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 3506.8035\n",
      "Epoch 364/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 2815.7358\n",
      "Epoch 365/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 2520.2229\n",
      "Epoch 366/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 2128.1890\n",
      "Epoch 367/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 2666.0232\n",
      "Epoch 368/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1783.6526\n",
      "Epoch 369/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 1397.1433\n",
      "Epoch 370/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1568.9869\n",
      "Epoch 371/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1364.4393\n",
      "Epoch 372/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 2310.8882\n",
      "Epoch 373/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1574.6130\n",
      "Epoch 374/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1295.0901\n",
      "Epoch 375/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1387.6216\n",
      "Epoch 376/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1129.4954\n",
      "Epoch 377/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 971.0931\n",
      "Epoch 378/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 907.5988\n",
      "Epoch 379/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 839.5294\n",
      "Epoch 380/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 801.7988\n",
      "Epoch 381/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 745.1645\n",
      "Epoch 382/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 905.4427\n",
      "Epoch 383/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 716.2298\n",
      "Epoch 384/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 736.2112\n",
      "Epoch 385/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 712.5092\n",
      "Epoch 386/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 663.4880\n",
      "Epoch 387/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 652.9209\n",
      "Epoch 388/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 734.6931\n",
      "Epoch 389/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 545.8234\n",
      "Epoch 390/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 926.6789\n",
      "Epoch 391/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 759.2455\n",
      "Epoch 392/600\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 834.3731\n",
      "Epoch 393/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 583.1569\n",
      "Epoch 394/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 507.0451\n",
      "Epoch 395/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 436.2426\n",
      "Epoch 396/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 506.3987\n",
      "Epoch 397/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 521.5048\n",
      "Epoch 398/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 514.9168\n",
      "Epoch 399/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 509.5741\n",
      "Epoch 400/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 544.9351\n",
      "Epoch 401/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 473.8274\n",
      "Epoch 402/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 408.5927\n",
      "Epoch 403/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 498.5241\n",
      "Epoch 404/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 455.3365\n",
      "Epoch 405/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 483.1907\n",
      "Epoch 406/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 516.0474\n",
      "Epoch 407/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 458.9431\n",
      "Epoch 408/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 426.9185\n",
      "Epoch 409/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 461.3609\n",
      "Epoch 410/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 461.7864\n",
      "Epoch 411/600\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 490.9932\n",
      "Epoch 412/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 432.5219\n",
      "Epoch 413/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 400.5373\n",
      "Epoch 414/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 407.7408\n",
      "Epoch 415/600\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 452.9749\n",
      "Epoch 416/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 429.9269\n",
      "Epoch 417/600\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 465.7906\n",
      "Epoch 418/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 431.6164\n",
      "Epoch 419/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 401.9689\n",
      "Epoch 420/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 384.8746\n",
      "Epoch 421/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 414.5494\n",
      "Epoch 422/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 424.7143\n",
      "Epoch 423/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 481.4134\n",
      "Epoch 424/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 532.5469\n",
      "Epoch 425/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 405.0948\n",
      "Epoch 426/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 422.0798\n",
      "Epoch 427/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 391.2658\n",
      "Epoch 428/600\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 432.2940\n",
      "Epoch 429/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 412.4810\n",
      "Epoch 430/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 478.2269\n",
      "Epoch 431/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 422.0126\n",
      "Epoch 432/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 721.7371\n",
      "Epoch 433/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 809.9278\n",
      "Epoch 434/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 594.1147\n",
      "Epoch 435/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 472.4088\n",
      "Epoch 436/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 379.0151\n",
      "Epoch 437/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 472.1319\n",
      "Epoch 438/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 494.5923\n",
      "Epoch 439/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 425.5867\n",
      "Epoch 440/600\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 375.1566\n",
      "Epoch 441/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 445.9361\n",
      "Epoch 442/600\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 469.0511\n",
      "Epoch 443/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 375.2621\n",
      "Epoch 444/600\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 410.7006\n",
      "Epoch 445/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 381.7620\n",
      "Epoch 446/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 335.2154\n",
      "Epoch 447/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 396.4319\n",
      "Epoch 448/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 404.9752\n",
      "Epoch 449/600\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 379.3278\n",
      "Epoch 450/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 358.0004\n",
      "Epoch 451/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 350.0724\n",
      "Epoch 452/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 385.2608\n",
      "Epoch 453/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 302.4891\n",
      "Epoch 454/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 296.7289\n",
      "Epoch 455/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 314.1707\n",
      "Epoch 456/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 371.4370\n",
      "Epoch 457/600\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 372.7118\n",
      "Epoch 458/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 435.8040\n",
      "Epoch 459/600\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 386.5334\n",
      "Epoch 460/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 573.6042\n",
      "Epoch 461/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 318.6848\n",
      "Epoch 462/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 396.9247\n",
      "Epoch 463/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 415.4688\n",
      "Epoch 464/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 343.7064\n",
      "Epoch 465/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 377.1944\n",
      "Epoch 466/600\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 364.8357\n",
      "Epoch 467/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 379.1139\n",
      "Epoch 468/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 404.4182\n",
      "Epoch 469/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 432.5117\n",
      "Epoch 470/600\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 359.1136\n",
      "Epoch 471/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 319.8630\n",
      "Epoch 472/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 352.0605\n",
      "Epoch 473/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 397.4958\n",
      "Epoch 474/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 486.2625\n",
      "Epoch 475/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 428.0195\n",
      "Epoch 476/600\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 485.2414\n",
      "Epoch 477/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 508.9860\n",
      "Epoch 478/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 442.5717\n",
      "Epoch 479/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 453.1680\n",
      "Epoch 480/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 398.7722\n",
      "Epoch 481/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1248.8993\n",
      "Epoch 482/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 1173.8986\n",
      "Epoch 483/600\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 2085.6606\n",
      "Epoch 484/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 1736.5770\n",
      "Epoch 485/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 1022.5331\n",
      "Epoch 486/600\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 746.3350\n",
      "Epoch 487/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 1308.1110\n",
      "Epoch 488/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 956.9342\n",
      "Epoch 489/600\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 1409.1206\n",
      "Epoch 490/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 598.3121\n",
      "Epoch 491/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 427.3134\n",
      "Epoch 492/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 373.6014\n",
      "Epoch 493/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 364.7845\n",
      "Epoch 494/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 310.5469\n",
      "Epoch 495/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 371.1719\n",
      "Epoch 496/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 311.5254\n",
      "Epoch 497/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 347.2292\n",
      "Epoch 498/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 347.0247\n",
      "Epoch 499/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 306.6278\n",
      "Epoch 500/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 374.7758\n",
      "Epoch 501/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 351.9201\n",
      "Epoch 502/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 382.0715\n",
      "Epoch 503/600\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 390.9810\n",
      "Epoch 504/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 313.0295\n",
      "Epoch 505/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 483.7581\n",
      "Epoch 506/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 298.0096\n",
      "Epoch 507/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 338.8673\n",
      "Epoch 508/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 374.5983\n",
      "Epoch 509/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 319.8867\n",
      "Epoch 510/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 388.5383\n",
      "Epoch 511/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 321.9254\n",
      "Epoch 512/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 341.0743\n",
      "Epoch 513/600\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 402.7382\n",
      "Epoch 514/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 391.9302\n",
      "Epoch 515/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 320.3157\n",
      "Epoch 516/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 325.2013\n",
      "Epoch 517/600\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 321.7256\n",
      "Epoch 518/600\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 420.3878\n",
      "Epoch 519/600\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 318.2134\n",
      "Epoch 520/600\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 299.7384\n",
      "Epoch 521/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 273.4398\n",
      "Epoch 522/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 300.5717\n",
      "Epoch 523/600\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 327.0779\n",
      "Epoch 524/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 308.2258\n",
      "Epoch 525/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 350.1239\n",
      "Epoch 526/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 289.1324\n",
      "Epoch 527/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 330.6312\n",
      "Epoch 528/600\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 282.1791\n",
      "Epoch 529/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 310.0916\n",
      "Epoch 530/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 325.7399\n",
      "Epoch 531/600\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 308.9320\n",
      "Epoch 532/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 282.7422\n",
      "Epoch 533/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 296.5263\n",
      "Epoch 534/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 338.8715\n",
      "Epoch 535/600\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 311.3197\n",
      "Epoch 536/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 313.9493\n",
      "Epoch 537/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 283.1180\n",
      "Epoch 538/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 300.2695\n",
      "Epoch 539/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 288.5872\n",
      "Epoch 540/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 303.7278\n",
      "Epoch 541/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 451.9668\n",
      "Epoch 542/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 484.9237\n",
      "Epoch 543/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 438.3403\n",
      "Epoch 544/600\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 404.6588\n",
      "Epoch 545/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 401.4222\n",
      "Epoch 546/600\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 437.6790\n",
      "Epoch 547/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 387.6169\n",
      "Epoch 548/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 307.5811\n",
      "Epoch 549/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 277.2374\n",
      "Epoch 550/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 326.0778\n",
      "Epoch 551/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 360.5170\n",
      "Epoch 552/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 287.7921\n",
      "Epoch 553/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 327.7002\n",
      "Epoch 554/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 285.4844\n",
      "Epoch 555/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 333.0603\n",
      "Epoch 556/600\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 291.0039\n",
      "Epoch 557/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 250.5490\n",
      "Epoch 558/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 342.8702\n",
      "Epoch 559/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 336.1071\n",
      "Epoch 560/600\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 335.7927\n",
      "Epoch 561/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 274.1230\n",
      "Epoch 562/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 265.8336\n",
      "Epoch 563/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 383.2241\n",
      "Epoch 564/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 303.1896\n",
      "Epoch 565/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 263.7764\n",
      "Epoch 566/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 292.2201\n",
      "Epoch 567/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 329.1093\n",
      "Epoch 568/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 354.0618\n",
      "Epoch 569/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 337.1306\n",
      "Epoch 570/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 394.2204\n",
      "Epoch 571/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 352.7045\n",
      "Epoch 572/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 304.8697\n",
      "Epoch 573/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 381.5089\n",
      "Epoch 574/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 312.2618\n",
      "Epoch 575/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 336.9254\n",
      "Epoch 576/600\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 369.2892\n",
      "Epoch 577/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 317.7720\n",
      "Epoch 578/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 307.4157\n",
      "Epoch 579/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 282.2205\n",
      "Epoch 580/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 255.1846\n",
      "Epoch 581/600\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 298.0168\n",
      "Epoch 582/600\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 279.2499\n",
      "Epoch 583/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 301.6090\n",
      "Epoch 584/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 271.1183\n",
      "Epoch 585/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 256.1514\n",
      "Epoch 586/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 250.5335\n",
      "Epoch 587/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 276.4394\n",
      "Epoch 588/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 289.5372\n",
      "Epoch 589/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 392.2340\n",
      "Epoch 590/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 293.9869\n",
      "Epoch 591/600\n",
      "29/29 [==============================] - 1s 25ms/step - loss: 276.2267\n",
      "Epoch 592/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 305.2473\n",
      "Epoch 593/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 253.4268\n",
      "Epoch 594/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 264.6067\n",
      "Epoch 595/600\n",
      "29/29 [==============================] - 1s 23ms/step - loss: 246.3731\n",
      "Epoch 596/600\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 262.1762\n",
      "Epoch 597/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 252.3154\n",
      "Epoch 598/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 251.9748\n",
      "Epoch 599/600\n",
      "29/29 [==============================] - 1s 22ms/step - loss: 293.4248\n",
      "Epoch 600/600\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 351.3372\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2dac81d1250>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_model.fit(shifted_x_train, shifted_y_train , epochs = 600 , batch_size = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e18db7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101, 5, 43)\n"
     ]
    }
   ],
   "source": [
    "# Data shifts for the testing data.\n",
    "shifted_x_test = []\n",
    "for index in range(logs,test_x.shape[0]-1):\n",
    "    shifted_x_test.append(test_x_scaled[index - logs : index])\n",
    "shifted_x_test = np.array(shifted_x_test)\n",
    "\n",
    "print(shifted_x_test.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8c7b153d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 9ms/step - loss: 15418.5977\n",
      "4/4 [==============================] - 2s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "# Testing the model\n",
    "# y_test = learning_model(shifted_x_test)\n",
    "\n",
    "# print(y_test)\n",
    "test_yAdjusted = test_y[0:len(test_y)-logs]\n",
    "learning_model.evaluate(x=shifted_x_test, y=test_yAdjusted)\n",
    "predict = learning_model.predict(shifted_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e49b6338",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python38\\lib\\site-packages\\seaborn\\_oldcore.py:917: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  val in data\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not interpret value `date` for parameter `x`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [75], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m sns\u001b[39m.\u001b[39;49mscatterplot(data\u001b[39m=\u001b[39;49mshifted_x_test, x\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdate\u001b[39;49m\u001b[39m\"\u001b[39;49m, y\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mprecipitation\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\seaborn\\relational.py:742\u001b[0m, in \u001b[0;36mscatterplot\u001b[1;34m(data, x, y, hue, size, style, palette, hue_order, hue_norm, sizes, size_order, size_norm, markers, style_order, legend, ax, **kwargs)\u001b[0m\n\u001b[0;32m    732\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mscatterplot\u001b[39m(\n\u001b[0;32m    733\u001b[0m     data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m,\n\u001b[0;32m    734\u001b[0m     x\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, hue\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, size\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, style\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    738\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    739\u001b[0m ):\n\u001b[0;32m    741\u001b[0m     variables \u001b[39m=\u001b[39m _ScatterPlotter\u001b[39m.\u001b[39mget_semantics(\u001b[39mlocals\u001b[39m())\n\u001b[1;32m--> 742\u001b[0m     p \u001b[39m=\u001b[39m _ScatterPlotter(data\u001b[39m=\u001b[39;49mdata, variables\u001b[39m=\u001b[39;49mvariables, legend\u001b[39m=\u001b[39;49mlegend)\n\u001b[0;32m    744\u001b[0m     p\u001b[39m.\u001b[39mmap_hue(palette\u001b[39m=\u001b[39mpalette, order\u001b[39m=\u001b[39mhue_order, norm\u001b[39m=\u001b[39mhue_norm)\n\u001b[0;32m    745\u001b[0m     p\u001b[39m.\u001b[39mmap_size(sizes\u001b[39m=\u001b[39msizes, order\u001b[39m=\u001b[39msize_order, norm\u001b[39m=\u001b[39msize_norm)\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\seaborn\\relational.py:538\u001b[0m, in \u001b[0;36m_ScatterPlotter.__init__\u001b[1;34m(self, data, variables, legend)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, variables\u001b[39m=\u001b[39m{}, legend\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    530\u001b[0m \n\u001b[0;32m    531\u001b[0m     \u001b[39m# TODO this is messy, we want the mapping to be agnostic about\u001b[39;00m\n\u001b[0;32m    532\u001b[0m     \u001b[39m# the kind of plot to draw, but for the time being we need to set\u001b[39;00m\n\u001b[0;32m    533\u001b[0m     \u001b[39m# this information so the SizeMapping can use it\u001b[39;00m\n\u001b[0;32m    534\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_default_size_range \u001b[39m=\u001b[39m (\n\u001b[0;32m    535\u001b[0m         np\u001b[39m.\u001b[39mr_[\u001b[39m.5\u001b[39m, \u001b[39m2\u001b[39m] \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39msquare(mpl\u001b[39m.\u001b[39mrcParams[\u001b[39m\"\u001b[39m\u001b[39mlines.markersize\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    536\u001b[0m     )\n\u001b[1;32m--> 538\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(data\u001b[39m=\u001b[39;49mdata, variables\u001b[39m=\u001b[39;49mvariables)\n\u001b[0;32m    540\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlegend \u001b[39m=\u001b[39m legend\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\seaborn\\_oldcore.py:640\u001b[0m, in \u001b[0;36mVectorPlotter.__init__\u001b[1;34m(self, data, variables)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[39m# var_ordered is relevant only for categorical axis variables, and may\u001b[39;00m\n\u001b[0;32m    636\u001b[0m \u001b[39m# be better handled by an internal axis information object that tracks\u001b[39;00m\n\u001b[0;32m    637\u001b[0m \u001b[39m# such information and is set up by the scale_* methods. The analogous\u001b[39;00m\n\u001b[0;32m    638\u001b[0m \u001b[39m# information for numeric axes would be information about log scales.\u001b[39;00m\n\u001b[0;32m    639\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_var_ordered \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mx\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mFalse\u001b[39;00m}  \u001b[39m# alt., used DefaultDict\u001b[39;00m\n\u001b[1;32m--> 640\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49massign_variables(data, variables)\n\u001b[0;32m    642\u001b[0m \u001b[39mfor\u001b[39;00m var, \u001b[39mcls\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_semantic_mappings\u001b[39m.\u001b[39mitems():\n\u001b[0;32m    643\u001b[0m \n\u001b[0;32m    644\u001b[0m     \u001b[39m# Create the mapping function\u001b[39;00m\n\u001b[0;32m    645\u001b[0m     map_func \u001b[39m=\u001b[39m partial(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mmap, plotter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\seaborn\\_oldcore.py:701\u001b[0m, in \u001b[0;36mVectorPlotter.assign_variables\u001b[1;34m(self, data, variables)\u001b[0m\n\u001b[0;32m    699\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_format \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlong\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 701\u001b[0m     plot_data, variables \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_assign_variables_longform(\n\u001b[0;32m    702\u001b[0m         data, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mvariables,\n\u001b[0;32m    703\u001b[0m     )\n\u001b[0;32m    705\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mplot_data \u001b[39m=\u001b[39m plot_data\n\u001b[0;32m    706\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvariables \u001b[39m=\u001b[39m variables\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\seaborn\\_oldcore.py:938\u001b[0m, in \u001b[0;36mVectorPlotter._assign_variables_longform\u001b[1;34m(self, data, **kwargs)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(val, (\u001b[39mstr\u001b[39m, \u001b[39mbytes\u001b[39m)):\n\u001b[0;32m    934\u001b[0m \n\u001b[0;32m    935\u001b[0m     \u001b[39m# This looks like a column name but we don't know what it means!\u001b[39;00m\n\u001b[0;32m    937\u001b[0m     err \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not interpret value `\u001b[39m\u001b[39m{\u001b[39;00mval\u001b[39m}\u001b[39;00m\u001b[39m` for parameter `\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 938\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(err)\n\u001b[0;32m    940\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    941\u001b[0m \n\u001b[0;32m    942\u001b[0m     \u001b[39m# Otherwise, assume the value is itself data\u001b[39;00m\n\u001b[0;32m    943\u001b[0m \n\u001b[0;32m    944\u001b[0m     \u001b[39m# Raise when data object is present and a vector can't matched\u001b[39;00m\n\u001b[0;32m    945\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, pd\u001b[39m.\u001b[39mDataFrame) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(val, pd\u001b[39m.\u001b[39mSeries):\n",
      "\u001b[1;31mValueError\u001b[0m: Could not interpret value `date` for parameter `x`"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.scatterplot(data=shifted_x_test, x=\"date\", y=\"precipitation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
